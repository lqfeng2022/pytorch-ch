export default [
  { id: 0,
    name: "Chapter 0: Artificial Intelligence",
    quote: "A computer would deserve to be called intelligent if it could deceive a human into believing that it was human.", 
    author: "― Alan Turing wrote in 1950",
    image: "src/assets/cover_0.webp",
    title: "Here's the ChatGPT introduction from OpenAI homepage.", 
    description: "When ChatGPT-3.5 came out on November 30, 2022, it was the first time that AI impressed us by its human-like text. It can help with answering questions, writing essays, creating content, tutoring in various subjects, and even having casual conversations. Each version has improved in terms of understanding context, handling more complex queries, and generating more accurate and relevant responses. In short, ChatGPT is like having a smart, versatile assistant right at your fingertips."
  },
  { id: 1,
    name: "Chapter 1: TENSORs",
    quote: "Maxwell's equations… when rewritten using time as the fourth dimension, this rather awkward set of eight equations collapses into a single tensor equation. This is what a physicist calls 'beauty'.", 
    author: "― Michio Kaku",
    image: "src/assets/tesseract.jpg",
    title: "Model of A Tesseract (or hypercube), in an otherworldly setting | Robert Brook/Science Photo Library Art", 
    description: "This image represents a tesseract, a 4-dimensional hypercube. While we can't see the 4th dimension, this image gives us a 3D shadow. You can image a 4D flashlight shining onto our 3D space, and the tesseract positioned in the middle. similar to how a light casts a shadow of a 3D cube onto a 2D surface—resulting in two squares, one inside the other. In this image, the tesseract appears as a cube within a cube, connected at the corners. In 4D space, both cubes are actually the same size, with the connecting lines representing higher-dimensional relationships."
  },
  { id: 2,
    name: "Chapter 2: A Straight Line Model",
    quote: "The straight line belongs to men, the curved one to God.", 
    author: "― Antoni Gaudi",
    image: "src/assets/straight_lines.jpg",
    title: "'How To Draw Freakishly Straight Lines by Hand' - 'tatyanadeniz.com/straight-lines'", 
    description: "This drawing is all about straight lines creating a cool, spiraling pattern. It’s like a bunch of triangles and angles that pull you in towards the center. Even though it’s just straight lines, they come together in a way that feels almost like it’s moving or shifting as you look at it. It’s a great example of how straight lines can be used to create something that feels dynamic and alive, despite their rigid and orderly nature."
  },
  { id: 3,
    name: "Chapter 3: The Maths Behind (I)",
    quote: "Gradient descent can write code better than you. I'm sorry.",
    author: "― Andrej Karpathy",
    image: "src/assets/gradient_descent.jpeg",
    title: "GRADIENT DESCENT SIMULATION - TWO PARAMETERS",
    description: "This graph is a powerful visualization of how Gradient Descent operates when two parameters are involved. It shows the path the algorithm takes across the parameter space (θ₁ and θ₂) to minimize the loss function - Loss(θ₁,θ₂). The movement along the surface illustrates how the parameters are iteratively adjusted to reduce the loss, eventually converging to a point where the model is optimally trained."
  },
  { id: 4,
    name: "Chapter 4: A Binary Classification Model",
    quote: "At its core, machine learning is about learning to make predictions on the basis of data. It’s fundamentally about generalization, about forming rules that enable us to classify unseen examples.",
    author: "― Pedro Domingos’ book “The Master Algorithm” (2015)",
    image: "src/assets/classification.webp",
    title: "GRADIENT DESCENT SIMULATION - TWO PARAMETERS",
    description: "This image acts as a visual metaphor for how machine learning models, particularly neural networks, process input data to generate classified or simplified outputs. It illustrates the transformation of raw data into meaningful information through computational processes, which is fundamental to the operation of machine learning systems."
  },
  { id: 5,
    name: "Chapter 5: The Maths Behind (II)",
    quote: "The backpropagation algorithm is possibly the most important algorithm in deep learning.",
    author: "― John D. Kelleher, Deep Learning",
    image: "src/assets/backpropagation.webp",
    title: "Multilayer Perceptron architecture and our notation. Handmade sketch by D Goglia.",
    description: "This handmade sketch display a pretty basic architecture in deep learing, which we call it multiplayer perceptron (MLP), we'll cover it in our future model. Here this neural network is pretty simple, which has only one hidden layer with fully connected feed-forward. In last chapter, we built a neural network with this kind of simple architecure, here in this chapter, we'll talk about it deeper, especially the backpropagation, - a core algrithm behind neural networ."
  },
]