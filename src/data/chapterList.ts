export default [
  { id: 0,
    name: "Artificial Intelligence",
    link: "artificial-intelligence",
    items: [
      { id: 1, name: "What's AI" },
      { id: 2, name: "Machine Learning" },
      { id: 3, name: "Deep Learning" },
      { id: 4, name: "Neural Network" },
      { id: 5, name: "ML Frameworks and Libraries" },
      { id: 6, name: "PyTorch" },
      { id: 7, name: "Prerequisites" },
      { id: 8, name: "How to take this Course" },
    ],
  },
  { id: 1, 
    name: "TENSORs", 
    link: "tensors",
    items: [
      { id: 1, name: "scaler, Vector, MATRIX, TENSOR" },
      { id: 2, name: "Create Tensor" },
      { id: 3, name: "Tensor's Attributes" },
      { id: 4, name: "Tensor Operation" },
      { id: 5, name: "Tensor Manipulating" },
      { id: 6, name: "Tensor Transpose" },
      { id: 7, name: "Tensor Indexing" },
      { id: 8, name: "Tensor vs. NumPy Array" },
      { id: 9, name: "Tensor Reproducibility" },
      { id: 10, name: "Tensor on GPUs" }
    ]
   },
  { id: 2, 
    name: "A Straight Line Model", 
    link: "a-straight-line-model",
    items: [
      { id: 1, name: "- PyTorch Workflow" },
      { id: 2, name: "i. Prepare Data" },
      { id: 3, name: "ii. Build a Model" },
      { id: 4, name: "iii. Train and Test a Model" },
      { id: 5, name: "iv. Improve a Model" },
      { id: 6, name: "v. Save and Load a Model" },
    ]
  },
  { id: 3, 
    name: "The Maths Behind (I)", 
    link: "the-maths-behind-one",
    items: [
      { id: 1, name: "- Linear Regression" },
      { id: 2, name: "- Loss Function (MSA)" },
      { id: 3, name: "- Gradient Descent (GD)" },
      { id: 4, name: "- Stochastic Gradient Descent (SGD)" },
      { id: 5, name: "- Learning Rate (lr)" }
    ]
  },
  { id: 4, 
    name: "A Binary Classification Model", 
    link: "a-binary-classification-model",
    items: [
      { id: 1, name: "i. Prepare Data" },
      { id: 2, name: "ii. Build a Model" },
      { id: 3, name: "iii. Train and Test a Model" },
      { id: 4, name: "iv. Improve a Model" },
      { id: 5, name: "v. Save and Load a Model" },
    ]
  },
  { id: 5, 
    name: "The Maths Behind (II)", 
    link: "the-maths-behind-two",
    items: [
      { id: 1, name: "- Classification Problem" },
      { id: 2, name: "- Binary Classification Problem" },
      { id: 3, name: "- Loss Function (BCE)" },
      { id: 4, name: "- Sigmoid Function" },
      { id: 5, name: "- BackPropagation" },
      { id: 6, name: "- Activation Function (ReLU)" }
    ]
  },
  { id: 6, 
    name: "A CNN Model", 
    link: "a-cnn-model",
    items: [
      { id: 1, name: "i. Prepare Data" },
      { id: 2, name: "ii.Build a Model" },
      { id: 3, name: "iii.Train and Test a Model" },
      { id: 4, name: "iv. Improve a Model" },
      { id: 5, name: "v. Save and Load a Model" },
    ]
  },
  { id: 7, 
    name: "The Maths Behind (III)", 
    link: "the-maths-behind-three",
    items: [
      { id: 1, name: "- Computer Vision" },
      { id: 2, name: "- Image Encoder" },
      { id: 3, name: "- MNIST Dataset" },
      { id: 4, name: "- DATALOADER" },
      { id: 5, name: "- ARGMAX Function" },
      { id: 6, name: "- Convolutional Neural Network (CNN)" },
      { id: 7, name: "- MaxPooling Layer" },
      { id: 8, name: "- SoftMax Function"}
    ]
  },
  { id: 8, 
    name: "A Vision Transformer Model", 
    link: "a-vit-model",
    items: [
      { id: 1, name: "i. Prepare Data" },
      { id: 2, name: "ii. Build a Model" },
      { id: 3, name: "iii. Train and Test a Model" },
      { id: 4, name: "iv. Improve a Model" },
      { id: 5, name: "v. Save and Load a Model" },
    ]
  },
  { id: 9, 
    name: "The Maths Behind (IV)", 
    link: "the-maths-behind-four",
    items: [
      { id: 1, name: "- Vision Transformer" },
      { id: 2, name: "- ViT Architecture" },
      { id: 3, name: "- Patch Embedding (Epat)" },
      { id: 4, name: "-- Class Token Embedding" },
      { id: 5, name: "- Positional Embedding (Epos)" },
      { id: 6, name: "- Transformer Encoder" },
      { id: 7, name: "-- Attention Mechanism" },
      { id: 8, name: "-- Multi-Head Self-Attention (MHA)" },
      { id: 9, name: "-- Layer Normalization (LN)" },
      { id: 10, name: "-- Residual Connection (+)" },
      { id: 11, name: "-- Multi-Layer Perceptron (MLP)" },
      { id: 12, name: "-- Perceptron" },
      { id: 13, name: "-- Dropout Layer" },
      { id: 14, name: "- Classifier" },
      { id: 15, name: "- Activation Function (GeLU)" },
    ]
  },
  { id: 10, 
    name: "A Language Translation Model", 
    link: "a-language-translation-model",
    items: [
      { id: 1, name: "i. Prepare Data" },
      { id: 2, name: "ii. Build a Model" },
      { id: 3, name: "iii. Train and Test a Model" },
      { id: 4, name: "iv. Improve a Model" },
      { id: 5, name: "v. Save and Load a Model" },
    ]
  },
  { id: 11, 
    name: "The Maths Behind (V)", 
    link: "the-maths-behind-five",
    items: [
      { id: 1, name: "- Word Embedding" },
      { id: 2, name: "- Recurrent Neural Network (RNN)"},
      { id: 3, name: "- Long Short-Term Memory (LSTM)"},
      { id: 4, name: "- Transformer" },
      { id: 5, name: "- Masked Multi-Head Attention" },
      { id: 6, name: "- Transformer Encoder" },
      { id: 7, name: "- Transformer Decoder" },
    ]
  },
]