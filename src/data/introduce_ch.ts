export default [
  { id: 0, 
    name: "内容介绍",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "本书的最终目标是为了帮助大家如何使用 Transformer 架构构建深度学习模型, Transformer 是 ChatGPT 中的那个 T - ChatGPT 的核心架构。在这本书中, 我按照 PyTorch 的基本工作流程构建了五个深度学习模型, 从简单的线性模型开始, 到卷积神经网络, 到自然语言处理, 到最后我们将使用 Transformer 架构构建一个英语中文翻译模型。在我们构建每一个模型之后, 我会用一个章节来详细介绍该模型背后涉及的数学知识和一些机器学习的核心概念。通过这门课程, 我希望大家不仅仅可以构建深度学习模型, 还对其背后的数学原理了如指掌。只有这样, 大家才会举一反三, 用已有的技能和知识去构建未知的更复杂的新模型。所谓授人以鱼不如授人以渔, 不外如此。"
      },
    ]
  },
  { id: 1,
    name: "本书背后的故事",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "一切始于 ChatGPT。"
      },
      { id: 1,
        title: "",
        value: "在 ChatGPT-3.5 发布之前, 我对人工智能的看法还很传统。尽管此前我已经构建过几个很基础的数据分析模型, 但那时我仍然认为 AI 离真正的“智能”还很远, 大家更喜欢叫它“人工智障”。在我看来, 它只是在特定领域表现优异, 比如计算机视觉中的人脸识别, 其他方面与传统代码相差甚大, 也可以说是各有千秋吧。在 2015 年 AlphaGo 战胜围棋世界冠军时, 我也并不觉得它有多么智能, 可替代人类什么的, 那就是个笑话。不过或许那时的我还从没有接触过人工智能, 不了解 AI 真正的潜力, 所以当时的观点很有局限性。"
      },
      { id: 2, 
        title: "",
        value: "当 ChatGPT-3.5 于 2022 年 11 月 30 日发布后不久, 因为太多人讨论从而吸引了我的注意力。这是 AI 第一次真正让我惊讶于其全面的处理能力, 特别是对自然语言的理解程度相当高, 所以给出的答案也相当准确, 在某些领域也超过一些专业软件, 比如翻译能力, 甚至编程能力。在我向 ChatGPT 提问时, 有那么一瞬间, 我觉得自己不是在和一台机器对话, 而是和一个真正懂我的人交流。比如我想用英文表达一些内容, 在给了 GPT 一堆有很多错误的文字并让它帮忙润色后, GPT 回了我一段相当流利的且完全合乎我表达内容和口吻的的文本, 且贴心地加入了些我表达上的不足之处。我只想说 GPT 太懂我了, 特别对于一个不善言辞的I人来说, 福音啊。"
      },
      { id: 3, 
        title: "",
        value: "从某种意义上来说, 它在很多方面比大多数人都要聪明。这让我觉得, 某种意义上来说图灵测试或许已经通过了。这个想法既让人着迷, 又有些不安。不过, 我相信我们正处于一个伴随着新的机遇和可能性的时代, 了解它, 接受它, 利用它, 成就自我, 或许才是一个好的选择, 否则可以只会被取代了。"
      },
      { id: 4, 
        title: "",
        value: "“WINTER IS COMING”, 人工智能也一样。为此我迫切想要了解为什么 ChatGPT 表现得如此智能, 支撑它的核心算法是什么。出于种种好奇心, 我开始去了解人工智能, 这其中自然而然地注意到了 Google 在 2017 年发表的论文《Attention Is All You Need》, 它提出的 Transformer 架构正是 ChatGPT 的基础。"
      },
      { id: 5, 
        title: "",
        value: "理解这个架构是学习 ChatGPT 及类似大语言模型的第一步。然而, 要真正理解 Transformer 并不容易。为此, 我查阅了大量的资料, 阅读了许多论文, 还看了无数关于深度学习基础概念和数学原理的教学视频。"
      },
      { id: 6, 
        title: "",
        value: "不过, 仅仅做一些研究、阅读论文或观看教学教程还不足以真正了解 Transformer。最好的方法是还是实践。所以, 我用PyTorch构建了一系列深度学习模型, 从最基础的模型入手, 比如简单的线性回归和一个二元分类问题。然后, 我又构建了几个稍稍复杂的模型, 比如10个手写数字的识别模型和一个使用 Transformer 编码器的图片识别模型, 最后是使用 Transformer 编码器和解码器的英文中文翻译模型。"
      },
    ]
  },
  { id: 2,
    name: "关于本书的内容",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "你可以将本书看作一个以实战课程为主, 教学为辅的深度学习课程, 其最终目的是引导你构建一个基于 Transformer 架构的语言翻译模型。"
      },
      { id: 1, 
        title: "",
        value: "这门课程只是一把钥匙, 一把打开深度学习大门的钥匙。拿到这把钥匙之后, 你可以去探索更广阔的人工智能机器学习的世界, 可以去挑战一些人类还没有解决的问题, 探索一些新的领域, 这虽然很困难, 充满挑战, 但至少有了某种可能性, 不是吗。想象一下, 创建一个可以将喵语翻译为人类语言的模型, 让我们可以知道猫的所思所想, 和猫沟通是不是很酷, 或许新时代的“御兽师”就会在你们之中诞生。很多以前只会出现在影视作品中的奇人异士或许会以另一种更加震撼的方式来到我们的世界, 当然也有很大可能带来某种不可控的后果。就某种意义上来说, 这种未来的不确定性和可能性也是充满魅力的, 毕竟无聊的世界真的很无聊。"
      },
      { id: 2,
        title: "",
        value: "这里, 我会从零开始带领大家步入人工智能深度学习的大门。本书一共十二个章节四个部分：第一部分聊聊人工智能的基本概念, 第二部分是张量 - 一个强大的数据处理的工具, 第三部份是五个深度学习模型, 第四部分是每个模型背后的数学原理分析。"
      },
    ]
  },
  { id: 3,
    name: "第一部分: 人工智能介绍",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "这一部分, 我们将探讨人工智能的历史, 说说它是如何从早期的图灵测试中的一个概念发展到 ChatGPT这一跨时代的人工智能产品的。其中主要涉及到人工智能、机器学习、深度学习和神经网络等基本概念。由于 ChatGPT 是基于深度学习的大语言模型, 所以我们将重点介绍深度学习的基础架构及其相关的基本知识。接下来, 我们将介绍一些流行且实用的机器学习库和框架。本书中所有模型均使用 PyTorch 框架来构建。"
      },
    ]
  },
  { id: 4, 
    name: "第二部分: 张量 - 数据处理的必备工具",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "在构建深度学习模型之前, 我们需要了解如何处理数据, 因为数据就像厨师的食材, 是任何美味佳肴的基础。在计算机科学中, 数据可以表示我们物质世界中的一切, 从文字、声音到图像和视频。张量是一个强大的工具, 它能够用来表示任何种类、任何复杂性的数据。",
      },
      { id: 1,
        title: "",
        value: "在这一部分, 我们首先介绍什么是张量。张量本质上是一个多维数组, 我们需要了解它的重要属性, 比如形状、维度数、数据类型以及它运行的设备。接下来, 我们将逐步了解一些基本的张量运算法则, 如加减法乘除法则, 以及稍微复杂一点的矩阵乘法（我们会详细解释这一部分）。另外我们还会学习一些简单的所谓的聚合操作, 比如在张量中查找最大值或最小值等等。",
      },
      { id: 2, 
        title: "",
        value: "接下来, 我们将重点介绍如何使用一些很实用的 PyTorch 方法来处理数据。例如, 我们可以将一个高维度张量降为一个低维度张量, 或延伸至高维度, 即我们常说的升维和降维, 在深度学习领域我们会频繁使用此方法。另外我们还可以沿着一个新的维度将两个或多个张量堆栈在一起, 或者沿着一个已有维度将它们放在一起。你还会学习如何改变张量的数据类型和其运行设备 (GPUs/CPU)。这些操作方法在整个模型构建和训练过程中都非常有用。"
      },
      { id: 3, 
        title: "",
        value: "我们还会介绍张量索引, 比如我们可以通过一个过滤器 (filter) 来访问任何的单个元素、一列、多列、一行、多行或特定的数据子集。此外, 我们还会讨论随机性, 或者更具体地说是伪随机性。为了确在运行相同代码时得到相同的结果, 我们可以使用一个称之为随机种子 (random seed) 的参数 - 一个整数。最后, 我们将讨论数据运行的设备。默认情况下, 张量在 CPU 上运行, 但如果可能, 我们更趋于使用 GPU 来加速操作。"
      },
    ]
  },
  { id: 5, 
    name: "第三部分: 5个深度学习模型",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "在这一部分, 我们将构建一系列深度学习模型, 探索机器学习的世界。这是本书最核心的部分, 所有其他章节都是围绕此部分展开的, 因为实践是最好的老师。通过实际构建深度学习模型, 我们不仅能够学会如何构建训练微调模型, 还可以灵活运用一些数学函数和基本架构。仅仅了解函数和深度学习架构是远远不够的, 你需要实操, 需要去实际地解决某个问题。",
      },
      { id: 1, 
        title: "",
        value: "如果一开始就让大家构建一个自然语言模型, 很多人都会放弃, 即使我对该模型进行透彻的分析和重构。所以这里, 我们那从最简单的开始, 然后一点点追加更多的数学函数, 更多的基本架构。我们的第一个模型是一条直线, 或者说一个线性方程, 这个模型的目标是找到一个符合目标函数的线性方程。之后, 我们会构建一个稍微复杂的模型 - 一个二元分类模型, 这个模型将帮助我们区分两组环状分布的数据集合。在这个项目中。",
      },
      { id: 2, 
        title: "",
        value: "第三个是一个手写数字识别模型。为此, 我们将构建一个卷积神经网络 (CNN) 来识别从 0 到 9 的数字。这里的重点是 CNN 架构, 它是计算机视觉任务的基石。然后, 我们将创建一个计算机视觉的  Transformer 模型, 用于图片分类。在这里, 我们将第一次引入 Transformer 架构, 虽然只是编码器, 但它几乎包含了所有的 Transformer 架构核心和细节。最后, 我们会使用 Transformer 的编码器和解码器共同构建一个英文中文翻译模型。",
      },
    ]
  },
  { id: 6,
    name: "第四部份: 模型背后的数学分析",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "一般说来, 在学习深度学习之前都要求有一定的数学基础, 这个是必须的, 我很认同。但是数学过于浩瀚, 特别是我们需要学习数学领域包含了微积分, 线性代数, 还有概率和统计, 我们真的有必要学习这里面的所有知识吗。作为一个普通人, 我很讨厌学习, 特别是一些你永远都不会用到的知识。知识是用来解决实际问题的, 不能解决实际问题的知识, 没必要浪费时间。 所以在课程设计上, 我选择以实际项目为主, 数学为辅的原则来安排章节。当我们在构建模型的时, 会遇到一些数学公式和基本概念 (有些你可能知道, 有些你可能没有接触过), 这个时候我会在这一部份 - “模型背后的数学分析” - 详细讲解, 而且我们只讲解模型用到的数学函数和相关知识。所以, 我们没有必要去学习所有的数学知识了, 当然你也可以去拓展你的数学知识体系 - 以我讲解的数学知识为原点 -, 这很重要。不过, 作为一个初学者, 我们可以先从简单的开始。",
      },
    ]
  },
  { id: 7,
    name: "说说形状",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "在构建五个深度学习模型的时候, 我们需要时时刻关注一件事：形状。我们已经知道, 形状是张量的一个重要属性, 它在模型构建中有至关重要的作用。本书有别与一般深度学习课程, 每当我构建一个模型的时候, 我都会给出该模型的数据形状, 从输入层、隐藏层, 一直到输出层。"
      },
      { id: 1, 
        title: "",
        value: "我这样做的原因很简单：我希望通过形状来可视化模型的架构, 这有助于我们比较清晰地了解数据在模型中流动和转换时候的变化, 特别是当我们构建的模型越来越复杂的时候。计算机喜欢数据, 而人类更喜欢图片。赋予数据以形状, 我们可以更直观地了解整个模型。相比于纯粹的数字、代码和文字描叙, 形状可以让我们更容易理解模型背后的想法。"
      },
      { id: 2, 
        title: "",
        value: "在这本书中, 每当我构建一个模型之后, 我都会单独用一个章节来介绍它背后的数学原理。个人认为这是本书中唯一稍微有些许挑战的部分。构建和训练模型就像烹饪美食, 一般说来我们按照食谱烹饪就可以了, 但如果你要你的菜肴更加美味, 你可能需要研发新的食谱, 更换更好的食材, 或者改变火候和器具等等。而深度学习模型同样如此, 然而改进模型的前提是, 你必须彻底地理解模型, 而其背后的数学原理是核心。我们可以说一个深度学习模型完全就是一个数学模型, 数学是钥匙, 找到这把钥匙, 拥有这把钥匙, 然后你可以使用这把钥匙去进行各种尝试。"
      },
      { id: 3, 
        title: "",
        value: "既然我们已经知道数学是开启机器学习大门的钥匙, 那我们该如何学习并掌握它呢？我们需要记住那些复杂的公式吗？不, 那是最low的。而且即使你记住了公式, 如果不理解其背后的意义, 你仍然无法正确使用它们。相反, 你应该专注于理解, 比如理解参数是如何影响公式的。在如今这个由 AI 驱动的世界, 特别是像 ChatGPT 这样工具的问世, 记忆知识已经越来越微不足道了。真正重要的是理解这些知识, 这些函数背后的意义, 并知道如何将它们应用于特定的场景, 比如构建深度学习模型, 这才是重点。"
      },
      { id: 3, 
        title: "",
        value: "因此, 在我们的数学原理课程中, 我赋予每个数学函数以形状 (曲线图)。这些形状可能是钟形、S形、下坡形等等。记住这些公式的形状很容易, 而当你将公式的参数与它们的形状关联时, 你就能快速掌握其背后的含义。例如正态分布, 通常表示为钟形, 我更喜欢叫它山形 (钟似乎都一个样, 没有山的诸多变化)。其中一个参数 - 均值 确定了山的位置, 而方差则决定了山的形状。想象一下, 一个方差较小山 (桂林的山大多如此) 通常陡峭狭窄, 而方差较大的山 (富士山) 都会宽阔平滑得多。"
      },
    ]
  },
]