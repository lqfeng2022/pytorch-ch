export default [
  { id: 0, 
    name: "内容介绍",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "本书的唯一目的是为了帮助大家对 Transformer 架构有一个比较清晰的认知, Transformer 是 ChatGPT 中的那个 T - ChatGPT 的核心架构。在这本书中, 我按照 PyTorch 的基本工作流程构建了五个深度学习模型，从一个简单的线性模型开始，到卷积神经网络, 到自然语言处理, 我们将使用 Transformer 架构构建一个英语法语翻译模型。在我们构建每一个模型之后, 我会用一个章节来介绍该模型背后涉及的数学知识和计算机科学的核心概念。只有这样, 我们才可以真正掌握该模型, 做到既可以构建这个模型, 也对该模型的每一个细节都了如指掌, 还可以举一反三, 运用该模型中学到的知识去构建相似的或者有共同之处的新的模型。"
      },
    ]
  },
  { id: 1,
    name: "这本书背后的故事",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "是什么激发我写这本书？说实话，一切始于 ChatGPT。"
      },
      { id: 1,
        title: "",
        value: "在 ChatGPT-3.5 发布之前，我对人工智能的看法还比较传统。尽管此前我已经构建过几个很基础的数据分析模型，但那时我仍然认为 AI 离真正的“智能”还很远, 大家更喜欢叫它“人工智障”。在我看来，它只是一段会处理重复任务的代码, 不比传统代码优秀多少, 只能说各有千秋, 就像工厂的机械手臂一样, 在特定领域它真的很实用。即使在 2015 年 AlphaGo 战胜围棋世界冠军时，我也并不觉得它有多么智能, 可以替代人类什么的。不过那时的我还从未没有接触过人工智能, 不了解 AI 真正的潜力，所以当时的观点有局限性。"
      },
      { id: 2, 
        title: "",
        value: "当 ChatGPT-3.5 于 2022 年 11 月 30 日催出之后不久，我开始关注它, 这是 AI 第一次真正让我惊讶于其类似人类的回答提问的方式, 而且相当准确, 在某些领域甚至超过一些专业模型, 比喻自然语言翻译能力, 还有编程的能力。当我向 ChatGPT 提问时, 有那么一瞬间, 或许只是短短一秒钟, 我觉得自己不是在和一台机器对话，而是在和一个可以真正懂我的人交流, 比如我想用英文表达一些内容, 然后我给了 GPT 一堆有很多错误的段落并附加一些指令, GPT 回了我一个很通顺的且完全合乎我表达内容的的段落, 并且还补充了一些我表达上的不足之处, 我只想说 GPT 太懂我了, 特别对弈一个不善言辞的I人来说, 简直就是福音啊。不过，有时候它也会一本正经的胡说八道，这个时候你必须反复确认, 然后去检索它给的答案, 再三确认其正确性。虽然很多人诟病这一点, 但是反过来想, 很多时候我们人类自己不也是如此吗, GPT 前期训练时或许也学习了这一点吧, 毕竟给它的数据算是整个人类知识的集合体吧, 里面当然也充斥着一个有人类特色的小小性格。"
      },
      { id: 3, 
        title: "",
        value: "从某种意义上来说，我确认它在很多方面比大多数人都要聪明。这让我思考，对于大多数人来说，图灵测试或许已经通过了。这个想法既让人着迷，又有些令人不安。不过，我相信我们正处于一个伴随着新的机遇和诸多可能的时代, 了解它, 接受它, 利用它, 成就自我, 或许才是一个号的选择, 否则可以只会被取代了。"
      },
      { id: 4, 
        title: "",
        value: "“WINTER IS COMING”，人工智能如此, 所以我也来了。为此我迫切得想要了解为什么 ChatGPT 表现得如此智能，支撑它的核心算法是什么呢。出于这种好奇心，我深入到了人工智能的世界, 注意到了 Google 在 2017 年发表的具有开创性意义的论文《Attention Is All You Need》，它提出的‘Transformer’架构正是 ChatGPT 的基础。"
      },
      { id: 5, 
        title: "",
        value: "理解这个架构是掌握 ChatGPT 及类似大语言模型的关键。然而，要精通 Transformer 架构并不容易。为此，我查阅了大量的资料，阅读了许多论文，还看了无数关于深度学习基础概念和数学原理的教学视频。"
      },
      { id: 6, 
        title: "",
        value: "不过，仅仅做一些研究、阅读论文或观看教学教程还不足以真正了解 Transformer。最好的学习方法是通过实践。所以，我用PyTorch构建了一系列深度学习模型，从最基础的模型入手，比如简单的线性回归和一个二元分类问题。然后，我又构建了几个稍稍复杂的模型，比如10个手写数字的识别模型和一个使用 Transformer 编码器的图片识别模型，最后是使用 Transformer 编码器和解码器的英文法语翻译模型。"
      },
    ]
  },
  { id: 2,
    name: "关于本书的内容",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "你可以将这本书视为一个训练课程，其最终目标是引导你构建一个基于 Transformer 架构的语言翻译模型。当然, 你可以使用 去构建更多的类似的模型, 你也可以去探索更多不同的架构去构建不同类型的模型。授人以鱼不如授人以渔, 理解了基本的深度学习知识, 基本的模型构建训练微调流程, 你就可以去探索新的架构, 新的模型。"
      },
      { id: 1, 
        title: "",
        value: "你还可以突破界限，探索一些新的领域。想象一下，创建一个可以将猫语和人类语言转译的模型，让我们能够和猫沟通, 虽然猫的智商哨笛, 表达和理解不了复杂的语言, 但是至少可以做一些很简单和基本的交流, 或许新时代的“御兽师”就会在你们之中诞生。很多以前只出现在影视作品中的奇人异士或许会以另外一种方式出现在我们的世界, 当然也可能带来不可控的灾难, 就某种意义上来说, 这种未来的不确定性和可能性也是充满魅力的, 毕竟无聊的世界真的很无聊。"
      },
      { id: 2, 
        title: "",
        value: "这里, 我将从零开始带领大家步入人工智能深度学习的大门。本书涵盖四个主要部分：第一部分时人工智能的基本概念，第二部分是张量(一个数据处理的强大工具)，第三部份是五个深度学习模型，以及第四部分的模型背后的数学原理分析。"
      },
    ]
  },
  { id: 3,
    name: "第一部分: 人工智能介绍",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "这一部分，我们将探讨人工智能的历史，以及它如何从早期的图灵测试等理念发展到 ChatGPT。随着这一领域的进步，机器学习、深度学习和神经网络等概念逐渐涌现。由于 ChatGPT 是基于深度学习的大语言模型，所以我们将重点介绍深度学习的基础架构及其相关的基本知识。"
      },
      { id: 1, 
        title: "",
        value: "接下来，我们将介绍一些流行且实用的机器学习库和框架。本书中所有模型均使用 PyTorch 框架来构建。"
      },
    ]
  },
  { id: 4, 
    name: "第二部分: 张量 - 数据处理的必备工具",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "在构建深度学习模型之前，我们需要了解如何操作数据，因为数据就像厨师的食材, 是任何美味佳肴的基础。在计算机科学中，数据可以表示我们物质世界中的一切，从文字、声音到图像和视频。张量是一个强大的工具，它能够用来表示任何种类任何复杂性的数据。",
      },
      { id: 1,
        title: "",
        value: "在这一部分，我们首先介绍什么是张量。张量本质上是一个多维数组，我们需要了解它的重要属性，比如形状、维度数量、数据类型以及它运行的设备。接下来，我们将深入了解一些基本的张量运算法则，如加法、减法、除法、乘法，以及稍微复杂一点的矩阵乘法（我们会详细解释）。另外我们还会学习一些简单的聚合操作，比如在张量中查找最大值或最小值, 等等。",
      },
      { id: 2, 
        title: "",
        value: "接下来，我们将重点介绍如何使用一些很实用的 PyTorch 方法来操作数据。例如，我们可以将一个高纬度张量降为一个较低维度张量，或扩展其到更高维度, 即我们常说的升纬和降纬, 在深度学习领域我们会频繁使用该运算。另外我们还可以沿着一个新的维度将两个或更多张量堆叠在一起，或者沿着现有维度将它们放在在一起。你还会学习如何改变张量的数据类型和运行设备(GPUs/CPU)。这些操作方法在整个模型构建和训练过程中都非常有用。"
      },
      { id: 3, 
        title: "",
        value: "我们还会介绍张量索引，我们通过过滤器来访问任何单个元素、一列、多列、一行、多行或特定的数据子集。此外，我们还会讨论随机性，或者更具体地说，计算机科学中的伪随机性。为了确在运行相同代码时得到相同的结果，我们可以使用一个称为随机种子（random seed）的参数，它是一个整数。最后，我们将讨论数据运行的设备。默认情况下，张量在 CPU 上运行，但如果可用，我们也能使用 GPU 来加速操作。"
      },
    ]
  },
  { id: 5, 
    name: "第三部分: 5个深度学习模型",
    value: "",
    image: "",
    content: [
      { id: 0, 
        title: "",
        value: "在这一部分中，我们将构建一系列深度学习模型，探索机器学习的世界。这是本书最激动人心的部分，因为实践是最好的老师。通过实际构建深度学习模型，你不仅能够掌握关键技能，还能深入理解复杂的概念和数学函数。仅仅了解函数和深度学习架构并不足以精通, 你需要实操。",
      },
      { id: 1, 
        title: "",
        value: "如果一开始就让你构建一个自然语言模型，大家可能都会放弃。 不过我们那可以从最简单的模型开始。所以，我门的第一个模型是一条直线, 或者说一个线性方程，该模型的目标是找到一个最符合目标函数的线性方程。接下来，我们会构建一个稍微复杂的模型 - 二元分类模型。这个模型将帮助我们区分两组圆环状分布的数据集合。在这个项目中，我们会引入第一个非线性函数，一个对于深度学习模型很重要的函数。",
      },
      { id: 2, 
        title: "",
        value: "第三个是手写数字识别模型。我们将构建一个卷积神经网络（CNN），来识别从 0 到 9 的数字。这里的重点是 CNN 架构，它是计算机视觉任务的基础。然后，我们将创建一个视觉 Transformer 模型，用于将图像分类。在这里, 我们将第一次介绍 Transformer 架构, 虽然只是编码器，但也几乎包含了所有的 Transformer 细节和核心。最后，我们将使用 Transformer 的编码器和解码器构建一个语言翻译模型, 这也是 ChatGPT 背后的核心架构。",
      },
    ]
  },
  { id: 6,
    name: "第四部份: 模型背后的数学分析",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "一般说来, 在学习深度学习之前都要求掌握一定的数学知识, 这个是必须的, 我很认同。但是数学浩瀚, 特别是我门需要学习微积分, 线性代数, 还有概率和统计, 我们真的有必要学习所有的知识吗, 作为一个普通人, 我很讨厌学习, 特别是一些你永远都不会用到的知识。 知识是用来解决实际问题的, 不能解决实际问题的知识, 没必要浪费时间。 所以在课程设计上, 我选择以实际项目为主, 数学为辅的原则来安排。当我们在构建模型的时候会遇到一些我们不懂的数学公式和概念, 这个时候我会在这一部份 - “模型背后的数学分析” -  每个模型之后的那一个章节中详细解释。这样, 我们就没有必要去学习那么多数学知识了, 我们只学习我们运用到的知识, 当然你也可以以此为点去拓展你的数学知识体系, 这很重要。 不过, 作为一个初学者, 我们可以先从简单的开始。",
      },
    ]
  },
  { id: 7,
    name: "关于形状",
    value: "",
    image: "",
    content: [
      { id: 0,
        title: "",
        value: "在构建五个深度学习模型的时候，我们需要时长关注一件事：形状。我们已经知道，形状是张量的一个重要属性，它在模型构建中有至关重要的作用。本书有别与一般深度学习课程, 每当我构建一个模型的时候，我都会描绘该模型的数据形状, 从输入层、隐藏层，一直到输出层。"
      },
      { id: 1, 
        title: "",
        value: "我这样做的原因很简单：我希望通过形状来可视化模型的架构, 这有助于我们比较清晰地了解数据在模型中流动和转换时候的变化, 特别是当我们构建的模型越来越复杂的时候。计算机喜欢数据，而人类更喜欢图片。赋予数据以形状，我们可以更直观地了解整个模型。所以相比于纯粹的数字、代码和文字描叙，形状可以让我们更容易理解模型背后的想法。"
      },
      { id: 2, 
        title: "",
        value: "在这本书中，每当我构建一个模型之后，我都会单独用一个章节来介绍它背后的数学原理。个人认为这是本书中唯一稍微有些许挑战的部分。构建和训练模型就像烹饪美食, 一般说来我们按照食谱烹饪就可以了, 但如果你要你的菜肴更加美味，你可能需要研发新的食谱, 或者更换食材, 或者改变火候和器具等等。而深度学习模型同样如此, 然而改进模型的前提是，你必须彻底地理解模型, 而其背后的数学原理是核心。我们可以说一个深度学习模型完全就是一个数学模型, 数学是钥匙，找到这把钥匙，拥有这把钥匙，然后你可以使用这把钥匙去尝试着改进你的模型。"
      },
      { id: 3, 
        title: "",
        value: "既然我们已经知道数学是开启机器学习大门的钥匙，那我们该如何学习并掌握它呢？我们需要记住那些复杂的公式吗？不，那是最low的方式。而且即使你记住了公式，如果不理解其背后的意义，你仍然无法正确使用它们。相反，你应该专注于理解, 比如理解参数是如何影响公式的。在如今这个由 AI 驱动的世界，特别是像 ChatGPT 这样工具的问世，记忆知识已经越来越微不足道了。真正重要的是理解这些知识, 这些函数背后的意义，并知道如何将它们应用于特定的场景，比如构建深度学习模型，这才是重点。"
      },
      { id: 3, 
        title: "",
        value: "因此，在我们的数学原理课程中，我赋予每个数学公式以形状(曲线图)。这些形状可能是钟形、S形、下坡形等等。记住这些公式的形状很容易，而当你将公式的参数与它们的形状关联时，你就能快速掌握其背后的含义。例如正态分布，通常表示为钟形，我更喜欢叫它山形。其中一个参数-均值确定了山的位置，而方差则决定了山的形状。想象一下，一个方差较小山通常陡峭狭窄，而方差较大的山(富士山)都会宽阔平滑得多。"
      },
    ]
  },
]